# INKE
ESWC 2025 paper: Inductive Higher Order Embeddings


Nested knowledge graphs (NKGs) encode facts in which subjects or objects can be triples, introducing a hierarchy of relationships beyond traditional entity-to-entity links. This nested structure creates challenges for established knowledge graph embedding (KGE) models, as it requires reasoning not just over entities and their relations, but also over triples as first-class citizens and higher-order (meta) relations connecting them. In addition, real-world scenarios require
inductive reasoning: at test time, new triples, new entities, and even new predicates may appear unseen during training. Traditional closed-world assumptions of many KGE models fail to accommodate such evolving and dynamic graphs. We introduce INKE (Inductive Nested Knowledge Embeddings), a novel framework that integrates three interconnected graph neural networks (GNNs) to address these challenges. INKE operates on multiple layers of abstraction: (i) A KG-GNN produces embeddings for entities and relations, capturing local semantic structures. (ii) A Line-GNN refines these embeddings at the triple level, using a line graph representation to model dependencies among triples. (iii) A Relation-GNN operates on a relation graph to handle predicate-level embeddings, enabling inductive generalization to unseen predicates and meta-relations. INKE achieves robust and flexible inductive reasoning capabilities in nested knowledge graphs
